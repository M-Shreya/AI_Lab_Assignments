{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4QEATrz94m6c",
        "outputId": "39af7be9-324a-4741-be1b-a688f8c406c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Case 1: Identical Documents\n",
            "Comparing: 'the quick brown fox jumps over the lazy dog' with 'the quick brown fox jumps over the lazy dog', Edit Distance: 0\n",
            "Comparing: 'it swiftly runs across the yard' with 'it swiftly runs across the yard', Edit Distance: 0\n",
            "Comparing: 'testing examples are essential for validation' with 'testing examples are essential for validation', Edit Distance: 0\n",
            "[('the quick brown fox jumps over the lazy dog', 'the quick brown fox jumps over the lazy dog'), ('it swiftly runs across the yard', 'it swiftly runs across the yard'), ('testing examples are essential for validation', 'testing examples are essential for validation')]\n",
            "\n",
            "Test Case 2: Slightly Modified Document\n",
            "Comparing: 'it swiftly runs across the yard' with 'a fast brown fox leaps over a lazy dog', Edit Distance: 31\n",
            "Comparing: 'it swiftly runs across the yard' with 'it quickly moves through the field', Edit Distance: 17\n",
            "Comparing: 'testing examples are essential for validation' with 'it quickly moves through the field', Edit Distance: 35\n",
            "Comparing: 'testing examples are essential for validation' with 'example tests are important for verification', Edit Distance: 26\n",
            "[]\n",
            "\n",
            "Test Case 3: Completely Different Documents\n",
            "Comparing: 'it swiftly runs across the yard' with 'this document is completely unrelated', Edit Distance: 30\n",
            "Comparing: 'testing examples are essential for validation' with 'this document is completely unrelated', Edit Distance: 35\n",
            "Comparing: 'testing examples are essential for validation' with 'there are no similarities here', Edit Distance: 34\n",
            "[]\n",
            "\n",
            "Test Case 4: Partial Overlap\n",
            "Comparing: 'the quick brown fox jumps over the lazy dog' with 'the quick brown fox jumps over the lazy dog', Edit Distance: 0\n",
            "Comparing: 'it swiftly runs across the yard' with 'the quick brown fox jumps over the lazy dog', Edit Distance: 31\n",
            "Comparing: 'it swiftly runs across the yard' with 'another random sentence', Edit Distance: 25\n",
            "Comparing: 'testing examples are essential for validation' with 'testing examples are essential for validation', Edit Distance: 0\n",
            "[('the quick brown fox jumps over the lazy dog', 'the quick brown fox jumps over the lazy dog'), ('testing examples are essential for validation', 'testing examples are essential for validation')]\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import heapq\n",
        "\n",
        "def clean_and_tokenize_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^\\w\\s.]', '', text)\n",
        "    sentences = text.split('.')\n",
        "    sentences = [sentence.strip() for sentence in sentences if sentence.strip()]\n",
        "    return sentences\n",
        "\n",
        "def calculate_edit_distance(str1, str2):\n",
        "    len_str1, len_str2 = len(str1), len(str2)\n",
        "    dp = [[0] * (len_str2 + 1) for _ in range(len_str1 + 1)]\n",
        "\n",
        "    for i in range(len_str1 + 1):\n",
        "        dp[i][0] = i\n",
        "    for j in range(len_str2 + 1):\n",
        "        dp[0][j] = j\n",
        "\n",
        "    for i in range(1, len_str1 + 1):\n",
        "        for j in range(1, len_str2 + 1):\n",
        "            if str1[i - 1] == str2[j - 1]:\n",
        "                dp[i][j] = dp[i - 1][j - 1]\n",
        "            else:\n",
        "                dp[i][j] = min(dp[i - 1][j] + 1, dp[i][j - 1] + 1, dp[i - 1][j - 1] + 1)\n",
        "\n",
        "    return dp[len_str1][len_str2]\n",
        "\n",
        "class AlignmentState:\n",
        "    def __init__(self, index1, index2, cost, parent=None):\n",
        "        self.index1 = index1\n",
        "        self.index2 = index2\n",
        "        self.cost = cost\n",
        "        self.parent = parent\n",
        "\n",
        "    def __lt__(self, other):\n",
        "        return self.cost < other.cost\n",
        "\n",
        "def perform_a_star_alignment(doc1, doc2):\n",
        "    initial_state = AlignmentState(0, 0, 0)\n",
        "    open_set = []\n",
        "    heapq.heappush(open_set, (0, initial_state))\n",
        "    closed_set = set()\n",
        "\n",
        "    while open_set:\n",
        "        _, current_state = heapq.heappop(open_set)\n",
        "\n",
        "        if current_state.index1 == len(doc1) and current_state.index2 == len(doc2):\n",
        "            return current_state\n",
        "\n",
        "        closed_set.add((current_state.index1, current_state.index2))\n",
        "\n",
        "        if current_state.index1 < len(doc1) and current_state.index2 < len(doc2):\n",
        "            sentence1 = doc1[current_state.index1]\n",
        "            sentence2 = doc2[current_state.index2]\n",
        "            new_cost = current_state.cost + calculate_edit_distance(sentence1, sentence2)\n",
        "            new_state = AlignmentState(current_state.index1 + 1, current_state.index2 + 1, new_cost, current_state)\n",
        "            if (new_state.index1, new_state.index2) not in closed_set:\n",
        "                heapq.heappush(open_set, (new_state.cost, new_state))\n",
        "\n",
        "        if current_state.index1 < len(doc1):\n",
        "            new_cost = current_state.cost + 1\n",
        "            new_state = AlignmentState(current_state.index1 + 1, current_state.index2, new_cost, current_state)\n",
        "            if (new_state.index1, new_state.index2) not in closed_set:\n",
        "                heapq.heappush(open_set, (new_state.cost, new_state))\n",
        "\n",
        "        if current_state.index2 < len(doc2):\n",
        "            new_cost = current_state.cost + 1\n",
        "            new_state = AlignmentState(current_state.index1, current_state.index2 + 1, new_cost, current_state)\n",
        "            if (new_state.index1, new_state.index2) not in closed_set:\n",
        "                heapq.heappush(open_set, (new_state.cost, new_state))\n",
        "\n",
        "    return None\n",
        "\n",
        "def backtrack_alignment_path(goal_state, doc1, doc2):\n",
        "    alignment_result = []\n",
        "    current = goal_state\n",
        "\n",
        "    while current:\n",
        "        idx1, idx2 = current.index1, current.index2\n",
        "        if idx1 > 0 and idx2 > 0:\n",
        "            alignment_result.append((doc1[idx1 - 1], doc2[idx2 - 1]))\n",
        "        elif idx1 > 0:\n",
        "            alignment_result.append((doc1[idx1 - 1], \"-\"))\n",
        "        elif idx2 > 0:\n",
        "            alignment_result.append((\"-\", doc2[idx2 - 1]))\n",
        "        current = current.parent\n",
        "\n",
        "    alignment_result.reverse()\n",
        "    return alignment_result\n",
        "\n",
        "def plagiarism_check(doc1, doc2):\n",
        "    processed_doc1 = clean_and_tokenize_text(doc1)\n",
        "    processed_doc2 = clean_and_tokenize_text(doc2)\n",
        "\n",
        "    goal_state = perform_a_star_alignment(processed_doc1, processed_doc2)\n",
        "\n",
        "    if goal_state is None:\n",
        "        print(\"No alignment found.\")\n",
        "        return []\n",
        "\n",
        "    alignment = backtrack_alignment_path(goal_state, processed_doc1, processed_doc2)\n",
        "\n",
        "    detected_plagiarism = []\n",
        "    for sentence1, sentence2 in alignment:\n",
        "        if sentence1 != \"-\" and sentence2 != \"-\":\n",
        "            dist = calculate_edit_distance(sentence1, sentence2)\n",
        "            print(f\"Comparing: '{sentence1}' with '{sentence2}', Edit Distance: {dist}\")\n",
        "            if dist < len(sentence1) * 0.5:\n",
        "                detected_plagiarism.append((sentence1, sentence2))\n",
        "\n",
        "    return detected_plagiarism\n",
        "\n",
        "doc1 = \"The quick brown fox jumps over the lazy dog. It swiftly runs across the yard. Testing examples are essential for validation.\"\n",
        "doc2 = \"A fast brown fox leaps over a lazy dog. It quickly moves through the field. Example tests are important for verification.\"\n",
        "\n",
        "doc1_identical = doc1\n",
        "doc2_identical = doc1\n",
        "print(\"Test Case 1: Identical Documents\")\n",
        "print(plagiarism_check(doc1_identical, doc2_identical))\n",
        "\n",
        "print(\"\\nTest Case 2: Slightly Modified Document\")\n",
        "print(plagiarism_check(doc1, doc2))\n",
        "\n",
        "doc3 = \"This document is completely unrelated. There are no similarities here.\"\n",
        "print(\"\\nTest Case 3: Completely Different Documents\")\n",
        "print(plagiarism_check(doc1, doc3))\n",
        "\n",
        "doc4 = \"The quick brown fox jumps over the lazy dog. Another random sentence. Testing examples are essential for validation.\"\n",
        "print(\"\\nTest Case 4: Partial Overlap\")\n",
        "print(plagiarism_check(doc1, doc4))\n"
      ]
    }
  ]
}